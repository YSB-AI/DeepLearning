{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Translator.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"JcJJofzv5ebp","executionInfo":{"status":"ok","timestamp":1599547996358,"user_tz":-60,"elapsed":4676,"user":{"displayName":"yaniel barbosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjeEwoPVbOEW9Pwf_Z5Q-LyxKX0GvQrJ-S-pfKh=s64","userId":"13057870575473273651"}},"outputId":"a898e250-edaa-4cef-f925-9e193beeb3e1","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["\n","%tensorflow_version 2.x\n","\n","!pip install simplejson\n","import simplejson as json\n","import tensorflow as tf\n","strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.python.keras.preprocessing.text import Tokenizer\n","from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.python.keras.layers import Dense, Reshape, Activation, Dropout, Input,  LSTM, Embedding,Flatten,Bidirectional, TimeDistributed,RepeatVector,Permute,Concatenate,Multiply\n","from tensorflow.python.keras.models import load_model, Model,Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","import os\n","import multiprocessing\n","from google.colab import drive\n","from random import seed , choice\n","import string\n","import re\n","import io\n","import pandas as pd\n","drive.mount('/content/drive')\n","from keras.utils.generic_utils import get_custom_objects\n","#print(tf.__version__)\n","#tf.enable_eager_execution() #Because is not Tensorflow 2\n","#tf.compat.v1.disable_eager_execution()\n","import configparser #https://docs.python.org/3/library/configparser.html\n","import time\n","\n","from sklearn.model_selection import train_test_split\n","\n","import os\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: simplejson in /usr/local/lib/python3.6/dist-packages (3.17.2)\n","INFO:tensorflow:Using MirroredStrategy with devices ('/device:CPU:0',)\n","INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:CPU:0',), communication = CollectiveCommunication.AUTO\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uK941ZBJMyte","executionInfo":{"status":"ok","timestamp":1599548007696,"user_tz":-60,"elapsed":15988,"user":{"displayName":"yaniel barbosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjeEwoPVbOEW9Pwf_Z5Q-LyxKX0GvQrJ-S-pfKh=s64","userId":"13057870575473273651"}},"outputId":"3187f44a-f06a-439c-c410-4ebafac19ffd","colab":{"base_uri":"https://localhost:8080/","height":714}},"source":["\n","try:\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n","except ValueError:\n","  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n","\n","tf.config.experimental_connect_to_cluster(tpu)\n","tf.tpu.experimental.initialize_tpu_system(tpu)\n","tpu_strategy = tf.distribute.TPUStrategy(tpu)\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running on TPU  ['10.52.252.178:8470']\n","INFO:tensorflow:Initializing the TPU system: grpc://10.52.252.178:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.52.252.178:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dEM7AYvnpGjM","executionInfo":{"status":"ok","timestamp":1599548007697,"user_tz":-60,"elapsed":15979,"user":{"displayName":"yaniel barbosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjeEwoPVbOEW9Pwf_Z5Q-LyxKX0GvQrJ-S-pfKh=s64","userId":"13057870575473273651"}},"outputId":"3bfbd881-ff63-4d2a-94b8-7b4ffe0a6f2b","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","print(tf.version)\n","config = configparser.ConfigParser()\n","config = {'dsize': 10000,'batch_size': 16*tpu_strategy.num_replicas_in_sync, \"emb_dim\":300, \"epochs\":50,\"sample_ignored\" : 1 }"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<module 'tensorflow._api.v2.version' from '/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v2/version/__init__.py'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"poxUineRvVsL"},"source":["\n","\"\"\"***************************** Get Word Embeddings *****************************\"\"\"\n","def get_word_embeddings(tokenizer_eng,vocab_len):\n","  embeddings_matrix = np.zeros((vocab_len,config['emb_dim']))\n","  f= open(\"/content/drive/My Drive/Colab Notebooks/Embeddings/glove.6B/glove.6B.\"+str(config['emb_dim'])+\"d.txt\")\n","\n","  for line in f:\n","      values = line.split()\n","      if(values[0] in tokenizer_eng.word_index):\n","          word = values[0]\n","          coefs = [float(i) for i in values[1:]]\n","          embeddings_matrix[tokenizer_eng.word_index[word],:] = coefs\n","  f.close()\n","  return embeddings_matrix\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tahwZv-LvV4V"},"source":["\n","\"\"\"***************************** Get Dataset - read file *****************************\"\"\"\n","def get_text():\n","  #http://www.datasciencemadesimple.com/strip-space-column-pandas-dataframe-leading-trailing-2/\n","  data = pd.DataFrame(columns=[\"ds_eng\", \"ds_pt\"])\n","  data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Portfolio/Translator/en-pt.bicleaner07.txt',  names=[\"ds_eng\", \"ds_pt\"],sep=\"\\t\", encoding='utf-8' ,nrows= config['dsize'])\n","  ind_eng=0\n","  ind_pt=0\n","  data.ds_eng =((\"<start> \"+((((data.ds_eng.str.replace('[^\\w\\s\\d+]','')).str.strip()).str.lower()).astype(str))+\" <end>\")).sort_values(axis=0, ascending=True) \n","  data.ds_pt = ((\"<start> \"+((((data.ds_pt.str.replace('[^\\w\\s\\d+]','')).str.strip()).str.lower()).astype(str))+\" <end>\")).sort_values(axis=0, ascending=True)\n","  \n","  return data\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3NBX19TvVo1"},"source":["\n","\"\"\"***************************** Get Tokens *****************************\"\"\"\n","def get_tokenized_dataset(data):\n","\n","  print(\"Train - Tokenizer get eng sentence: \" +str(data.ds_eng.tolist()[100]))\n","  print(\"Train - Tokenizer get pt labels: \"+ str(data.ds_pt.tolist()[100]))\n","\n","  tokenizer_eng = Tokenizer(filters='',oov_token=\"<oov>\")#filters: a string where each element is a character that will be filtered from the texts. The default is all punctuation, plus tabs and line breaks, minus the `'` character.\n","  tokenizer_pt = Tokenizer(filters='',oov_token=\"<oov>\")# <oov> for unknown words\n","\n","  tokenizer_eng.fit_on_texts(data.ds_eng) # Fit test\n","  tokenizer_pt.fit_on_texts(data.ds_pt)\n","\n","  token_eng = tokenizer_eng.texts_to_sequences(data.ds_eng) # Convert text to token\n","  token_pt = tokenizer_pt.texts_to_sequences(data.ds_pt)\n","\n","  print(\"tokenizer_eng : \",token_eng[100])\n","  print(\"tokenizer_pt : \",token_pt[100])\n","\n","  token_eng = pad_sequences(token_eng,padding='post')\n","  token_pt = pad_sequences(token_pt,padding='post')\n","  \n","  return tokenizer_eng,tokenizer_pt,token_eng,token_pt\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C2syOT6gQHLS","executionInfo":{"status":"ok","timestamp":1599548017793,"user_tz":-60,"elapsed":26020,"user":{"displayName":"yaniel barbosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjeEwoPVbOEW9Pwf_Z5Q-LyxKX0GvQrJ-S-pfKh=s64","userId":"13057870575473273651"}},"outputId":"d0bcc6f0-81e4-42bd-cf46-23fe94fd85c5","colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["\n","text = get_text()\n","\n","tokenizer_eng,tokenizer_token_pt, input_set,output_set  = get_tokenized_dataset(text)\n","train_input, val_input, train_output, val_output = train_test_split(input_set, output_set, test_size=0.1)\n","\n","vocab_len_eng = len(tokenizer_eng.word_index) + 1\n","vocab_len_pt = len(tokenizer_token_pt.word_index) + 1\n","\n","max_words_eng, max_words_pt = output_set.shape[1], input_set.shape[1]\n","embeddings_matrix = get_word_embeddings(tokenizer_eng,vocab_len_eng)\n","\n","print(\"input.shape\",input_set.shape)\n","print(\"output.shape\",output_set.shape)\n","print(\"train_input.shape\",train_input.shape)\n","print(\"train_output.shape\",train_output.shape)\n","print(\"val_input.shape\",val_input.shape)\n","print(\"val_output.shape\",val_output.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train - Tokenizer get eng sentence: <start> censorship cuba discs information internet networks offline singularity totalitarianism <end>\n","Train - Tokenizer get pt labels: <start> censura cuba discos informações internet redes desligado singularidade totalitarismo <end>\n","tokenizer_eng :  [3, 319, 272, 5037, 83, 183, 492, 549, 651, 401, 4]\n","tokenizer_pt :  [2, 196, 175, 2277, 170, 150, 349, 435, 387, 230, 3]\n","input.shape (10000, 304)\n","output.shape (10000, 182)\n","train_input.shape (9000, 304)\n","train_output.shape (9000, 182)\n","val_input.shape (1000, 304)\n","val_output.shape (1000, 182)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CakNq7Xxbab3","executionInfo":{"status":"ok","timestamp":1599548017990,"user_tz":-60,"elapsed":26205,"user":{"displayName":"yaniel barbosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjeEwoPVbOEW9Pwf_Z5Q-LyxKX0GvQrJ-S-pfKh=s64","userId":"13057870575473273651"}},"outputId":"b65257e2-7f9d-4079-a4c5-a1a72988a2f1","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_output_in=train_output[:,:(train_output.shape[1])-1]\n","train_output_out=train_output[:,1:(train_output.shape[1])]\n","\n","dataset = tf.data.Dataset.from_tensor_slices((train_input,train_output)).shuffle(len(train_input))\n","dataset = dataset.batch(config['batch_size'], drop_remainder=True) # drop_remainder - drop the last batch if it's smaller than batch_size\n","example_input_batch, example_target_batch_ = next(iter(dataset))\n","example_input_batch.shape, example_target_batch_.shape \n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([128, 304]), TensorShape([128, 182]))"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"jKwzb8LWov6-"},"source":["class Encoder(tf.keras.Model):\n","  def __init__(self, vocab_size,  enc_units, batch_sz):\n","    super(Encoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.enc_units = enc_units\n","    self.embedding = Embedding(vocab_size, config['emb_dim'], input_length=max_words_eng, weights=[embeddings_matrix],name =\"emb_layer\", trainable=False)\n","    self.lstm = LSTM(self.enc_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","\n","  def call(self, x, hidden):\n","    x = self.embedding(x)\n","    output, state_h , state_c= self.lstm(x, initial_state = hidden)\n","    return output, state_h, state_c\n","\n","  def initialize_hidden_state(self):\n","    return (tf.zeros([self.batch_sz, self.enc_units]),tf.zeros([self.batch_sz, self.enc_units]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mJ4AhlzXp08n"},"source":["class BahdanauAttention(tf.keras.layers.Layer):\n","  def __init__(self, units):\n","    super(BahdanauAttention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.V = tf.keras.layers.Dense(1)\n","\n","  def call(self, s1,s2, values):\n","    # we are doing this to broadcast addition along the time axis to calculate the score\n","    query = tf.concat([s1,s2], axis=-1)\n","    query_with_time_axis = tf.expand_dims(query, 1)\n","\n","    # score shape == (batch_size, max_length, 1)\n","    # we get 1 at the last axis because we are applying score to self.V\n","    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n","    score = self.V(tf.nn.tanh(\n","        self.W1(query_with_time_axis) + self.W2(values)))\n","\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    attention_weights = tf.nn.softmax(score, axis=1)\n","\n","    # context_vector shape after sum == (batch_size, hidden_size)\n","    context_vector = attention_weights * values\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","    return context_vector, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vCqH7_vhowYt"},"source":["class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","    super(Decoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.dec_units = dec_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.lstm = LSTM(self.dec_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","    # used for attention\n","    self.attention = BahdanauAttention(self.dec_units)\n","\n","  def call(self, x, hidden1,hidden2, enc_output):\n","    # enc_output shape == (batch_size, max_length, hidden_size)\n","    context_vector, attention_weights = self.attention(hidden1,hidden2, enc_output)\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","    x = self.embedding(x)\n","    \n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","    # passing the concatenated vector to the GRU\n","    output, state_h,state_c = self.lstm(x)\n","\n","    # output shape == (batch_size * 1, hidden_size)\n","    output = tf.reshape(output, (-1, output.shape[2]))\n","\n","    # output shape == (batch_size, vocab)\n","    x = self.fc(output)\n","\n","    return x, state_h,state_c, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FEZsoNiIGdeJ","executionInfo":{"status":"ok","timestamp":1599548030441,"user_tz":-60,"elapsed":38623,"user":{"displayName":"yaniel barbosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjeEwoPVbOEW9Pwf_Z5Q-LyxKX0GvQrJ-S-pfKh=s64","userId":"13057870575473273651"}},"outputId":"00d4b0ac-a2ef-45b9-c497-c3352d39d5ab","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["units=256\n","with tpu_strategy.scope():\n","  # Encoder\n","  encoder = Encoder(vocab_len_eng,  units, config['batch_size'])\n","  sample_hidden= encoder.initialize_hidden_state()\n","  sample_output, sample_hidden, sample_c = encoder(example_input_batch, sample_hidden)\n","  print('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","  print('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n","\n","\n","  # Attention\n","  attention_layer = BahdanauAttention(10)\n","  attention_result, attention_weights = attention_layer(sample_hidden, sample_c , sample_output)\n","\n","  print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n","  print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n","\n","  # Decoder\n","  decoder = Decoder(vocab_len_pt, 1, units, config['batch_size'])\n","  sample_decoder_output,_, _, _ = decoder(tf.random.uniform((config['batch_size'], 1)),sample_hidden, sample_c, sample_output)\n","  print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n","\n","  optimizer = Adam(0.0004)\n","  loss_object = SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n","  def loss_function(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    loss_ = loss_object(real, pred)\n","\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","\n","    return tf.reduce_mean(loss_)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Encoder output shape: (batch size, sequence length, units) (128, 304, 256)\n","Encoder Hidden state shape: (batch size, units) (128, 256)\n","Attention result shape: (batch size, units) (128, 256)\n","Attention weights shape: (batch_size, sequence_length, 1) (128, 304, 1)\n","Decoder output shape: (batch_size, vocab size) (128, 28520)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B7M_aPiXPRBk"},"source":["checkpoint_directory = \"/content/drive/My Drive/Colab Notebooks/Portfolio/Translator/keras_model_default/\"\n","checkpoint_prefix = os.path.join(checkpoint_directory, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,encoder=encoder, decoder=decoder)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gVghUVF-rKn_"},"source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","\n","  def _step(inp, targ, enc_hidden):\n","    loss = 0\n","    with tf.GradientTape() as tape:\n","      enc_output, enc_hidden,enc_c = encoder(inp, enc_hidden)\n","      \n","      dec_input = tf.expand_dims([tokenizer_token_pt.word_index['<start>']] * config['batch_size'], 1)\n","      # Teacher forcing - feeding the target as the next input\n","      for t in range(1, targ.shape[1]):\n","        # passing enc_output to the decoder\n","\n","        predictions, enc_hidden, enc_c , _ = decoder(dec_input, enc_hidden,enc_c, enc_output)\n","        tar = tf.expand_dims(targ[:, t], 1)\n","        loss += loss_function(tar, predictions)\n","        \n","        # using teacher forcing\n","        dec_input = tf.expand_dims(targ[:, t], 1)\n","    batch_loss = (loss / int(targ.shape[1]))\n","    variables = encoder.trainable_variables + decoder.trainable_variables\n","    gradients = tape.gradient(loss, variables)\n","    optimizer.apply_gradients(zip(gradients, variables))\n","    return batch_loss\n","\n","  per_replica_losses = tpu_strategy.run(_step,args=(inp, targ, enc_hidden,))\n","  batch_loss_tep = tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,axis=None)\n","  return batch_loss_tep"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TSfdJhdu5qij","outputId":"36a44f0b-e9ff-4d33-8d29-09c52d851df4","colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["EPOCHS = 1000\n","steps_per_epoch = len(train_input)//config['batch_size']\n","dataset = dataset.repeat(steps_per_epoch)\n","\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_loss = 0\n","  \n","  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","    total_loss += train_step(inp, targ, enc_hidden)\n","\n","  if epoch %20  ==0:\n","    print(\"Time taken for 1 epoch\",(time.time() - start),\"sec,  Epoch \",(epoch + 1),\" -> Loss \",total_loss)\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Time taken for 1 epoch 476.442444562912 sec,  Epoch  1  -> Loss  tf.Tensor(467.8415, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.42127847671509 sec,  Epoch  21  -> Loss  tf.Tensor(247.01292, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.4522430896759 sec,  Epoch  41  -> Loss  tf.Tensor(205.93108, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.43180322647095 sec,  Epoch  61  -> Loss  tf.Tensor(175.57333, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.41386389732361 sec,  Epoch  81  -> Loss  tf.Tensor(151.9371, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.495097160339355 sec,  Epoch  101  -> Loss  tf.Tensor(130.46304, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.43101692199707 sec,  Epoch  121  -> Loss  tf.Tensor(122.418274, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.43678283691406 sec,  Epoch  141  -> Loss  tf.Tensor(105.70312, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.45724391937256 sec,  Epoch  161  -> Loss  tf.Tensor(96.944305, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.41374921798706 sec,  Epoch  181  -> Loss  tf.Tensor(96.66806, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.436002254486084 sec,  Epoch  201  -> Loss  tf.Tensor(83.66193, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.43578624725342 sec,  Epoch  221  -> Loss  tf.Tensor(77.10756, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.444064140319824 sec,  Epoch  241  -> Loss  tf.Tensor(72.95495, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.442832708358765 sec,  Epoch  261  -> Loss  tf.Tensor(68.251526, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.456180572509766 sec,  Epoch  281  -> Loss  tf.Tensor(65.03089, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.456533908843994 sec,  Epoch  301  -> Loss  tf.Tensor(61.464214, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.43593215942383 sec,  Epoch  321  -> Loss  tf.Tensor(58.13573, shape=(), dtype=float32)\n","Time taken for 1 epoch 36.41868758201599 sec,  Epoch  341  -> Loss  tf.Tensor(54.75868, shape=(), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dH9z0MUtCwdm"},"source":["def evaluate(sentence):\n","  attention_plot = np.zeros((max_words_pt, max_words_eng))\n","\n","  #sentence = preprocess_sentence(sentence)\n","  print(sentence.split(' '))\n","  \n","  inputs = [tokenizer_eng.word_index[i] for i in sentence.split(' ') if i != '']\n","  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n","                                                         maxlen=max_words_eng,\n","                                                         padding='post')\n","  inputs = tf.convert_to_tensor(inputs)\n","\n","  result = ''\n","\n","  hidden = [tf.zeros((1, units)),tf.zeros((1, units))]\n","  enc_out, enc_hidden,enc_c = encoder(inputs, hidden)\n","\n","  dec_hidden = enc_hidden\n","  dec_input = tf.expand_dims([tokenizer_token_pt.word_index['<start>']], 0)\n","\n","  for t in range(max_words_pt):\n","    predictions, dec_hidden,_, attention_weights = decoder(dec_input, dec_hidden,enc_c,enc_out) \n","\n","    # storing the attention weights to plot later on\n","    attention_weights = tf.reshape(attention_weights, (-1, ))\n","    attention_plot[t] = attention_weights.numpy()\n","\n","    predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","    if predicted_id == 0:\n","      continue\n","      \n","    result += tokenizer_token_pt.index_word[predicted_id] + ' '\n","\n","    if tokenizer_token_pt.index_word[predicted_id] == '<end>':\n","      return result, sentence, attention_plot\n","\n","    # the predicted ID is fed back into the model\n","    dec_input = tf.expand_dims([predicted_id], 0)\n","\n","  return result, sentence, attention_plot\n","\n","def translate(sentence):\n","  result, sentence, attention_plot = evaluate(sentence)\n","\n","  print('Input: %s' % (sentence))\n","  print('Predicted translation: {}'.format(result))\n","\n","  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","  plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n","\n","import matplotlib.ticker as ticker\n","\n","def plot_attention(attention, sentence, predicted_sentence):\n","  fig = plt.figure(figsize=(10,10))\n","  ax = fig.add_subplot(1, 1, 1)\n","  ax.matshow(attention, cmap='viridis')\n","\n","  fontdict = {'fontsize': 14}\n","\n","  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n","  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n","\n","  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vgvzx6g3CHp7"},"source":["print(text.ds_eng.tolist()[201])\n","print(text.ds_pt.tolist()[201])\n","translate(\"the world largest building\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uCgcZv3jLMqt"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2-gdo9C5QOda"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PhYXXbCJ2a3I"},"source":["sentence = ['this','is','a','sentence']\n","sentence = ','.join(sentence)\n","print(sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9XPj2Bs5nscp"},"source":[""],"execution_count":null,"outputs":[]}]}