{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "de1753d1",
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.callbacks import ModelCheckpoint\n",
                "from tensorflow.keras.models import Model, load_model, Sequential\n",
                "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
                "from tensorflow.keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.metrics import Precision, Recall\n",
                "\n",
                "import tensorflow as tf\n",
                "import keras_tuner as kt\n",
                "from sklearn.model_selection import train_test_split\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f546b596",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys \n",
                "sys.path.append(\"..\")\n",
                "from RUN_TENSORBOARD import *\n",
                "\n",
                "# Launch TensorBoard to monitor training\n",
                "events_folder = \"./logs\"\n",
                "main(\"./logs\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "d9512e84",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training set shape: (29914, 431, 256), (29914, 105, 1)\n",
                        "Dev (Val) set shape: (3739, 431, 256), (3739, 105, 1)\n",
                        "Test set shape: (3740, 431, 256), (3740, 105, 1)\n",
                        "Calculated class weight factor for positives: 3.76\n"
                    ]
                }
            ],
            "source": [
                "import pickle \n",
                "\n",
                "# Load the preprocessed datasets\n",
                "with open('X.pkl', 'rb') as f:\n",
                "    X = pickle.load(f)\n",
                "\n",
                "with open('Y.pkl', 'rb') as f:\n",
                "    Y = pickle.load(f)\n",
                "\n",
                "# Perform Stratified Split: Train (80%), Val (10%), Test (10%)\n",
                "# Determine which samples have at least one trigger word for stratification\n",
                "y_has_trigger = np.any(Y > 0, axis=(1, 2))\n",
                "\n",
                "X_train, X_val_test, Y_train, Y_val_test = train_test_split(\n",
                "    X, Y, test_size=0.2, random_state=42, stratify=y_has_trigger\n",
                ")\n",
                "\n",
                "# Split the remaining 20% into 50% Val, 50% Test (10% total each)\n",
                "y_has_trigger_val = np.any(Y_val_test > 0, axis=(1, 2))\n",
                "X_val, X_test, Y_val, Y_test = train_test_split(\n",
                "    X_val_test, Y_val_test, test_size=0.5, random_state=42, stratify=y_has_trigger_val\n",
                ")\n",
                "\n",
                "print(f\"Training set shape: {X_train.shape}, {Y_train.shape}\")\n",
                "print(f\"Dev (Val) set shape: {X_val.shape}, {Y_val.shape}\")\n",
                "print(f\"Test set shape: {X_test.shape}, {Y_test.shape}\")\n",
                "\n",
                "# Handle Imbalance using Sample Weights\n",
                "def get_sample_weights(y, weight_factor=10.0):\n",
                "    \"\"\"\n",
                "    Calculate sample weights where positive timesteps get higher weight.\n",
                "    \"\"\"\n",
                "    # Initialize weights with 1.0\n",
                "    weights = np.ones(y.shape[:2])\n",
                "    # Apply higher weight to positive classes (1s)\n",
                "    # y shape is (samples, steps, 1), so squeeze to (samples, steps)\n",
                "    weights[y.squeeze() == 1] = weight_factor\n",
                "    return weights\n",
                "\n",
                "# Calculate dynamic weight factor based on ratio\n",
                "neg = np.sum(Y_train == 0)\n",
                "pos = np.sum(Y_train == 1)\n",
                "total = neg + pos\n",
                "w1 = (1 / pos) * (total / 2.0)\n",
                "w0 = (1 / neg) * (total / 2.0)\n",
                "# We will base our factor relative to w0 being approx 1, so factor ~ w1/w0\n",
                "weight_factor = w1 / w0\n",
                "print(f\"Calculated class weight factor for positives: {weight_factor:.2f}\")\n",
                "\n",
                "train_sample_weights = get_sample_weights(Y_train, weight_factor)\n",
                "val_sample_weights = get_sample_weights(Y_val, weight_factor)\n",
                "\n",
                "del X\n",
                "del Y\n",
                "del X_val_test\n",
                "del Y_val_test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "fc528aa2",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def build_model(hp):\n",
                "    \"\"\"\n",
                "    Build the trigger word detection model architecture with hyperparameter tuning.\n",
                "    \"\"\"\n",
                "    input_shape = (431, 256) # Tx, n_freq\n",
                "    X_input = Input(shape = input_shape)\n",
                "    \n",
                "    # Conv layer to extract features and downsample\n",
                "    filters = hp.Int('filters', min_value=128, max_value=512, step=32)\n",
                "    kernel_size = 15\n",
                "    \n",
                "    X = Conv1D(filters=filters, kernel_size=kernel_size, strides=4)(X_input)\n",
                "    X = BatchNormalization()(X)\n",
                "    X = Activation(\"relu\")(X)\n",
                "    X = Dropout(hp.Float('dropout_1', min_value=0.2, max_value=0.6, step=0.1))(X)\n",
                "\n",
                "    # First GRU layer to capture temporal patterns\n",
                "    gru_units_1 = hp.Int('gru_units_1', min_value=64, max_value=256, step=32)\n",
                "    X = GRU(gru_units_1, return_sequences=True)(X)\n",
                "    X = Dropout(hp.Float('dropout_2', min_value=0.2, max_value=0.6, step=0.1))(X)\n",
                "    X = BatchNormalization()(X)\n",
                "    \n",
                "    # Second GRU layer for deeper temporal modeling\n",
                "    gru_units_2 = hp.Int('gru_units_2', min_value=64, max_value=256, step=32)\n",
                "    X = GRU(gru_units_2, return_sequences=True)(X)\n",
                "    X = Dropout(hp.Float('dropout_3', min_value=0.2, max_value=0.6, step=0.1))(X)\n",
                "    X = BatchNormalization()(X)\n",
                "    X = Dropout(hp.Float('dropout_4', min_value=0.2, max_value=0.6, step=0.1))(X)\n",
                "    \n",
                "    # Output layer: probability per timestep\n",
                "    X = TimeDistributed(Dense(1, activation=\"sigmoid\"))(X)\n",
                "\n",
                "    model = Model(inputs = X_input, outputs = X)\n",
                "    \n",
                "    lr = hp.Choice('learning_rate', values=[1e-4, 1e-5, 1e-6])\n",
                "    opt = Adam(learning_rate=lr)\n",
                "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\", Precision(name='precision'), Recall(name='recall')])\n",
                "    \n",
                "    return model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "e2decbfd",
            "metadata": {},
            "outputs": [],
            "source": [
                "Tx = 431  # input timesteps\n",
                "n_freq = 256  # mel frequency bins\n",
                "Ty = 105  # output timesteps\n",
                "\n",
                "hop_length = 256 \n",
                "n_mels = 256\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "kt_setup",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Reloading Tuner from keras_tuner_logs/trigger_word_tuning/tuner0.json\n"
                    ]
                }
            ],
            "source": [
                "tuner = kt.BayesianOptimization(\n",
                "    build_model,\n",
                "    objective=[kt.Objective('val_loss', direction='min'),kt.Objective('val_precision', direction='max'),kt.Objective('val_recall', direction='max')],\n",
                "    max_trials=20,\n",
                "    executions_per_trial=1,\n",
                "    directory='keras_tuner_logs',\n",
                "    project_name='trigger_word_tuning',\n",
                "    overwrite=False \n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "kt_search",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Search: Running Trial #14\n",
                        "\n",
                        "Value             |Best Value So Far |Hyperparameter\n",
                        "384               |128               |filters\n",
                        "0.5               |0.5               |dropout_1\n",
                        "256               |96                |gru_units_1\n",
                        "0.4               |0.4               |dropout_2\n",
                        "64                |128               |gru_units_2\n",
                        "0.5               |0.4               |dropout_3\n",
                        "0.3               |0.5               |dropout_4\n",
                        "0.0001            |0.0001            |learning_rate\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "I0000 00:00:1770888836.676714   24331 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21265 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/100\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "I0000 00:00:1770888852.147185   25090 cuda_dnn.cc:529] Loaded cuDNN version 91001\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 15ms/step - accuracy: 0.6298 - loss: 1.0340 - precision: 0.3329 - recall: 0.7234 - val_accuracy: 0.7278 - val_loss: 0.7897 - val_precision: 0.4370 - val_recall: 0.9901\n",
                        "Epoch 2/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 15ms/step - accuracy: 0.8274 - loss: 0.5353 - precision: 0.5561 - recall: 0.9050 - val_accuracy: 0.8660 - val_loss: 0.4269 - val_precision: 0.6246 - val_recall: 0.9198\n",
                        "Epoch 3/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 15ms/step - accuracy: 0.8527 - loss: 0.4683 - precision: 0.5970 - recall: 0.9081 - val_accuracy: 0.8286 - val_loss: 0.4671 - val_precision: 0.5547 - val_recall: 0.9644\n",
                        "Epoch 4/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 15ms/step - accuracy: 0.8679 - loss: 0.4281 - precision: 0.6281 - recall: 0.9138 - val_accuracy: 0.8451 - val_loss: 0.4112 - val_precision: 0.5803 - val_recall: 0.9710\n",
                        "Epoch 5/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 15ms/step - accuracy: 0.8798 - loss: 0.3915 - precision: 0.6512 - recall: 0.9194 - val_accuracy: 0.8914 - val_loss: 0.3594 - val_precision: 0.6789 - val_recall: 0.9246\n",
                        "Epoch 6/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 15ms/step - accuracy: 0.8875 - loss: 0.3683 - precision: 0.6685 - recall: 0.9247 - val_accuracy: 0.9050 - val_loss: 0.3236 - val_precision: 0.7104 - val_recall: 0.9312\n",
                        "Epoch 7/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 15ms/step - accuracy: 0.8940 - loss: 0.3493 - precision: 0.6805 - recall: 0.9266 - val_accuracy: 0.8845 - val_loss: 0.3240 - val_precision: 0.6542 - val_recall: 0.9636\n",
                        "Epoch 8/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 15ms/step - accuracy: 0.8981 - loss: 0.3369 - precision: 0.6928 - recall: 0.9323 - val_accuracy: 0.9118 - val_loss: 0.3172 - val_precision: 0.7295 - val_recall: 0.9274\n",
                        "Epoch 9/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 15ms/step - accuracy: 0.9021 - loss: 0.3229 - precision: 0.6982 - recall: 0.9323 - val_accuracy: 0.9157 - val_loss: 0.2864 - val_precision: 0.7370 - val_recall: 0.9360\n",
                        "Epoch 10/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 15ms/step - accuracy: 0.9072 - loss: 0.3082 - precision: 0.7117 - recall: 0.9349 - val_accuracy: 0.9184 - val_loss: 0.2958 - val_precision: 0.7451 - val_recall: 0.9339\n",
                        "Epoch 11/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 15ms/step - accuracy: 0.9103 - loss: 0.3010 - precision: 0.7196 - recall: 0.9397 - val_accuracy: 0.9318 - val_loss: 0.2887 - val_precision: 0.7891 - val_recall: 0.9253\n",
                        "Epoch 12/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 15ms/step - accuracy: 0.9139 - loss: 0.2893 - precision: 0.7283 - recall: 0.9419 - val_accuracy: 0.9300 - val_loss: 0.2770 - val_precision: 0.7796 - val_recall: 0.9334\n",
                        "Epoch 13/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 15ms/step - accuracy: 0.9154 - loss: 0.2841 - precision: 0.7331 - recall: 0.9415 - val_accuracy: 0.9320 - val_loss: 0.2728 - val_precision: 0.7877 - val_recall: 0.9294\n",
                        "Epoch 14/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 15ms/step - accuracy: 0.9192 - loss: 0.2720 - precision: 0.7406 - recall: 0.9448 - val_accuracy: 0.9147 - val_loss: 0.2483 - val_precision: 0.7228 - val_recall: 0.9685\n",
                        "Epoch 15/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 15ms/step - accuracy: 0.9186 - loss: 0.2721 - precision: 0.7410 - recall: 0.9452 - val_accuracy: 0.9355 - val_loss: 0.2673 - val_precision: 0.7976 - val_recall: 0.9318\n",
                        "Epoch 16/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 15ms/step - accuracy: 0.9227 - loss: 0.2614 - precision: 0.7504 - recall: 0.9462 - val_accuracy: 0.9320 - val_loss: 0.2512 - val_precision: 0.7794 - val_recall: 0.9464\n",
                        "Epoch 17/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 15ms/step - accuracy: 0.9252 - loss: 0.2529 - precision: 0.7576 - recall: 0.9491 - val_accuracy: 0.9384 - val_loss: 0.2501 - val_precision: 0.8050 - val_recall: 0.9361\n",
                        "Epoch 18/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 15ms/step - accuracy: 0.9278 - loss: 0.2453 - precision: 0.7629 - recall: 0.9506 - val_accuracy: 0.9365 - val_loss: 0.2399 - val_precision: 0.7938 - val_recall: 0.9455\n",
                        "Epoch 19/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 15ms/step - accuracy: 0.9284 - loss: 0.2439 - precision: 0.7654 - recall: 0.9501 - val_accuracy: 0.9346 - val_loss: 0.2331 - val_precision: 0.7850 - val_recall: 0.9519\n",
                        "Epoch 20/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 15ms/step - accuracy: 0.9320 - loss: 0.2330 - precision: 0.7734 - recall: 0.9512 - val_accuracy: 0.9343 - val_loss: 0.2355 - val_precision: 0.7827 - val_recall: 0.9546\n",
                        "Epoch 21/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 15ms/step - accuracy: 0.9315 - loss: 0.2328 - precision: 0.7738 - recall: 0.9524 - val_accuracy: 0.9442 - val_loss: 0.2408 - val_precision: 0.8256 - val_recall: 0.9340\n",
                        "Epoch 22/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 15ms/step - accuracy: 0.9345 - loss: 0.2245 - precision: 0.7827 - recall: 0.9545 - val_accuracy: 0.9384 - val_loss: 0.2409 - val_precision: 0.8021 - val_recall: 0.9415\n",
                        "Epoch 23/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 15ms/step - accuracy: 0.9347 - loss: 0.2226 - precision: 0.7823 - recall: 0.9553 - val_accuracy: 0.9374 - val_loss: 0.2219 - val_precision: 0.7932 - val_recall: 0.9525\n",
                        "Epoch 24/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 15ms/step - accuracy: 0.9358 - loss: 0.2194 - precision: 0.7854 - recall: 0.9554 - val_accuracy: 0.9370 - val_loss: 0.2139 - val_precision: 0.7887 - val_recall: 0.9596\n",
                        "Epoch 25/100\n",
                        "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 15ms/step - accuracy: 0.9371 - loss: 0.2145 - precision: 0.7885 - recall: 0.9565 - val_accuracy: 0.9425 - val_loss: 0.2213 - val_precision: 0.8125 - val_recall: 0.9467\n",
                        "Epoch 26/100\n",
                        "\u001b[1m 215/3740\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9378 - loss: 0.2186 - precision: 0.7854 - recall: 0.9538"
                    ]
                }
            ],
            "source": [
                "callbacks_best = [\n",
                "    tf.keras.callbacks.TensorBoard(\n",
                "        log_dir=events_folder,\n",
                "        histogram_freq=1,\n",
                "        write_graph=True,\n",
                "        update_freq='batch'\n",
                "    ),\n",
                "    tf.keras.callbacks.EarlyStopping(\n",
                "        monitor='val_loss',\n",
                "        patience=40,\n",
                "        restore_best_weights=True\n",
                "    ),\n",
                "]\n",
                "\n",
                "tuner.search(\n",
                "    X_train, \n",
                "    Y_train, \n",
                "    epochs=100, \n",
                "    batch_size=8,\n",
                "    validation_data=(X_val, Y_val, val_sample_weights),\n",
                "    callbacks=callbacks_best,\n",
                "    sample_weight=train_sample_weights\n",
                ")\n",
                "\n",
                "# Get the optimal hyperparameters\n",
                "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
                "\n",
                "print(f\"\"\"\n",
                "The hyperparameter search is complete. The optimal number of filters in the first conv layer is {best_hps.get('filters')} \n",
                "and the optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "train_best",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
                "model = tuner.hypermodel.build(best_hps)\n",
                "\n",
                "# callbacks\n",
                "callbacks = [\n",
                "    tf.keras.callbacks.ModelCheckpoint('./keras_tuner_logs/best_model.keras', save_best_only=True, monitor='val_loss'),\n",
                "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
                "]\n",
                "\n",
                "history = model.fit(\n",
                "    X_train, \n",
                "    Y_train, \n",
                "    epochs=300, \n",
                "    validation_data=(X_val, Y_val, val_sample_weights),\n",
                "    callbacks=callbacks,\n",
                "    sample_weight=train_sample_weights\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "evaluate_test",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate on the Test set\n",
                "print(\"Evaluating on Test set...\")\n",
                "test_loss, test_acc, test_prec, test_recall = model.evaluate(X_test, Y_test)\n",
                "print(f\"Test Loss: {test_loss}\")\n",
                "print(f\"Test Accuracy: {test_acc}\")\n",
                "print(f\"Test Precision: {test_prec}\")\n",
                "print(f\"Test Recall: {test_recall}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d77e2324",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the best trained model\n",
                "model.load_weights('./keras_tuner_logs/best_model.keras')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c741903b",
            "metadata": {},
            "source": [
                "# Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "64c5ba1e",
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "from pydub import AudioSegment\n",
                "import matplotlib.pyplot as plt\n",
                "import librosa\n",
                "import numpy as np\n",
                "import IPython\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "72a8ba9b",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def get_mels_spectogram(file):\n",
                "    \"\"\"\n",
                "    Generate Mel spectrogram from an audio file.\n",
                "    \n",
                "    Args:\n",
                "        file (str): Path to the audio file\n",
                "        \n",
                "    Returns:\n",
                "        tuple: Contains:\n",
                "            - y_orig (np.ndarray): Original audio time series\n",
                "            - S_orig (np.ndarray): Mel spectrogram\n",
                "            - S_dB_orig (np.ndarray): Mel spectrogram in decibels\n",
                "            - sr (int): Sample rate of the audio file\n",
                "    \"\"\"\n",
                "    y_orig, sr = librosa.load(file)\n",
                "    S_orig = librosa.feature.melspectrogram(y=y_orig, sr=sr, n_mels=n_mels, hop_length=hop_length)\n",
                "    S_dB_orig = librosa.power_to_db(S_orig, ref=np.max)\n",
                "    return y_orig, S_orig, S_dB_orig, sr\n",
                "\n",
                "\n",
                "def match_target_amplitude(sound, target_dBFS):\n",
                "    \"\"\"\n",
                "    Adjust the volume of an audio segment to match a target amplitude level.\n",
                "    \n",
                "    Args:\n",
                "        sound (AudioSegment): Audio segment to adjust\n",
                "        target_dBFS (float): Target amplitude in decibels relative to full scale\n",
                "        \n",
                "    Returns:\n",
                "        AudioSegment: Audio segment with adjusted volume\n",
                "    \"\"\"\n",
                "    change_in_dBFS = target_dBFS - sound.dBFS\n",
                "    return sound.apply_gain(change_in_dBFS)\n",
                "\n",
                "\n",
                "def trigger_word_detections(filename, out_filename = \"tmp.wav\"):\n",
                "    \"\"\"\n",
                "    Detect trigger words in an audio file and visualize the results.\n",
                "    \n",
                "    Processes the audio file, generates predictions using the model, and plots\n",
                "    both the mel spectrogram and the prediction probabilities over time.\n",
                "    \n",
                "    Args:\n",
                "        filename (str): Path to input audio file\n",
                "        out_filename (str): Path for temporary normalized audio file (default: \"tmp.wav\")\n",
                "        \n",
                "    Returns:\n",
                "        np.ndarray: Model predictions with shape (1, timesteps, 1) containing\n",
                "                   probabilities of trigger word detection at each timestep\n",
                "    \"\"\"\n",
                "    fig, ax = plt.subplots(2, 1, figsize=(6, 4))\n",
                "    \n",
                "    # Normalize audio amplitude before processing\n",
                "    audio_clip = AudioSegment.from_wav(filename)\n",
                "    audio_clip = match_target_amplitude(audio_clip, -20.0)\n",
                "    \n",
                "    file_handle = audio_clip.export(out_filename, format=\"wav\")\n",
                "    y_gen, S_gen, S_dB_gen, sr = get_mels_spectogram(out_filename)\n",
                "\n",
                "    # Reshape spectrogram for model: (freqs, timesteps) -> (timesteps, freqs)\n",
                "    x = S_gen.swapaxes(0, 1)\n",
                "    x = np.expand_dims(x, axis=0)\n",
                "    print(x.shape)\n",
                "    predictions = model.predict(x)\n",
                "\n",
                "    # Plot spectrogram\n",
                "    librosa.display.specshow(S_dB_gen, sr=sr, x_axis='time', y_axis='mel', ax=ax[0], cmap='magma')\n",
                "\n",
                "    # Plot detection probabilities\n",
                "    ax[1].plot(predictions[0, :, 0])\n",
                "    ax[1].set_ylabel('probability')\n",
                "    plt.show()\n",
                "    \n",
                "    return predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f7d616a7",
            "metadata": {},
            "outputs": [],
            "source": [
                "file = \"./Dataset/training_set/train_2.wav\"\n",
                "IPython.display.Audio(file)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5a2c021b",
            "metadata": {},
            "outputs": [],
            "source": [
                "predictions  = trigger_word_detections(file)\n",
                "predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a8187586",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0c715336",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "155ff009",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ai_dev",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
